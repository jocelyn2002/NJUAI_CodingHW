{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Client: 'tcp://127.0.0.1:36741' processes=8 threads=8, memory=33.55 GB>",
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:36741</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>8</li>\n  <li><b>Cores: </b>8</li>\n  <li><b>Memory: </b>33.55 GB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,explained_variance_score\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dask.distributed import Client\n",
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline只用到gps定位数据，即train_gps_path\n",
    "train_gps_path = 'data/origin/train0523.csv'\n",
    "test_data_path = 'data/wash3_test.csv'\n",
    "order_data_path = 'data/wash1_event.csv'\n",
    "port_data_path = 'data/port_fixed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取前1000000行\n",
    "debug = True\n",
    "NDATA = 10000\n",
    "DELTA = 0\n",
    "# -3600*20: 3.2w\n",
    "# \n",
    "\n",
    "\n",
    "if debug:\n",
    "    train_data = pd.read_csv(train_gps_path,nrows=NDATA,header=None)\n",
    "else:\n",
    "    train_data = pd.read_csv(train_gps_path,header=None)\n",
    "\n",
    "train_data.columns = ['loadingOrder','carrierName','timestamp','longitude',\n",
    "                  'latitude','vesselMMSI','speed','direction','vesselNextport',\n",
    "                  'vesselNextportETA','vesselStatus','vesselDatasource','TRANSPORT_TRACE']\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "event_data = pd.read_csv(order_data_path)\n",
    "port = pd.read_csv(port_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, mode='train'):\n",
    "    \n",
    "    assert mode=='train' or mode=='test'\n",
    "    \n",
    "    if mode=='train':\n",
    "        data['vesselNextportETA'] = pd.to_datetime(data['vesselNextportETA'], infer_datetime_format=True)\n",
    "    elif mode=='test':\n",
    "        data['temp_timestamp'] = data['timestamp']\n",
    "        data['onboardDate'] = pd.to_datetime(data['onboardDate'], infer_datetime_format=True)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], infer_datetime_format=True)\n",
    "    data['longitude'] = data['longitude'].astype(float)\n",
    "    data['loadingOrder'] = data['loadingOrder'].astype(str)\n",
    "    data['latitude'] = data['latitude'].astype(float)\n",
    "    data['speed'] = data['speed'].astype(float)\n",
    "    data['direction'] = data['direction'].astype(float)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = get_data(train_data, mode='train')\n",
    "test_data = get_data(test_data, mode='test')\n",
    "event_data['timestamp'] = pd.to_datetime(event_data['timestamp'], infer_datetime_format=True, utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['end_lat', 'end_lon', 'begin_lat', 'begin_lon', 'anchor_cnt', 'anchor_ratio', 'latitude_min', 'latitude_max', 'latitude_mean', 'latitude_median', 'longitude_min', 'longitude_max', 'longitude_mean', 'longitude_median', 'speed_min', 'speed_max', 'speed_mean', 'speed_median', 'direction_min', 'direction_max', 'direction_mean', 'direction_median']\n"
    }
   ],
   "source": [
    "# 代码参考：https://github.com/juzstu/TianChi_HaiYang\n",
    "def get_feature(df, mode='train'):\n",
    "    \n",
    "    assert mode=='train' or mode=='test'\n",
    "    \n",
    "    df.sort_values(['loadingOrder', 'timestamp'], inplace=True)\n",
    "    # 特征只选择经纬度、速度\\方向\n",
    "    df['lat_diff'] = df.groupby('loadingOrder')['latitude'].diff(1)\n",
    "    df['lon_diff'] = df.groupby('loadingOrder')['longitude'].diff(1)\n",
    "    df['speed_diff'] = df.groupby('loadingOrder')['speed'].diff(1)\n",
    "    df['diff_minutes'] = df.groupby('loadingOrder')['timestamp'].diff(1).dt.total_seconds() // 60\n",
    "    \n",
    "    df = dd.from_pandas(df, npartitions=16)\n",
    "    df['anchor'] = df.apply(lambda x: 1 if x['lat_diff'] <= 0.03 and x['lon_diff'] <= 0.03\n",
    "                            and x['speed_diff'] <= 0.3 and x['diff_minutes'] <= 10 else 0, axis=1)\n",
    "    df = df.compute()\n",
    "    \n",
    "    #print(\"df:\",df)\n",
    "    if mode=='train':\n",
    "        group_df = df.groupby('loadingOrder')['timestamp'].agg(mmax='max', count='count', mmin='min').reset_index()\n",
    "        # 读取数据的最大值-最小值，即确认时间间隔为label\n",
    "        # group_df['label'] = (group_df['mmax'] - group_df['mmin']).dt.total_seconds()\n",
    "        # print(group_df)\n",
    "        \n",
    "        event_df = event_data[event_data['loadingOrder'].isin(group_df['loadingOrder'].values)][['loadingOrder','latitude','longitude','timestamp']]\n",
    "        #print(\"event: \",event_df)\n",
    "\n",
    "        tmp = pd.concat([df[['loadingOrder','latitude','longitude','timestamp']], event_df], axis=0, ignore_index=True)\n",
    "        #print(\"tmp:\",tmp)\n",
    "        \n",
    "        tmp['timestamp'] = pd.to_datetime(tmp['timestamp'], infer_datetime_format=True)\n",
    "        tmp.sort_values(['loadingOrder', 'timestamp'], inplace=True)\n",
    "        \n",
    "        tmp_time = tmp.groupby('loadingOrder')['timestamp'].agg(mmax='max', count='count', mmin='min').reset_index()\n",
    "        tmp_time['label'] = (tmp_time['mmax'] - tmp_time['mmin']).dt.total_seconds()\n",
    "        tmp_time = tmp_time[['loadingOrder','label']]\n",
    "        group_df = group_df.merge(tmp_time,on='loadingOrder',how='left')\n",
    "        # print(group_df)\n",
    "        \n",
    "        def func(order,lat,lon,tmp2):\n",
    "            if lat==200:\n",
    "                r = tmp2[tmp2['loadingOrder']==order][['latitude','longitude']].values\n",
    "                #print(\"r is:\", r)\n",
    "                return r[0][0],r[0][1]\n",
    "            else:\n",
    "                return lat,lon\n",
    "        # 增加终点经纬度\n",
    "        tmp_cord = tmp.groupby('loadingOrder')['latitude','longitude'].last().reset_index()\n",
    "        tmp_cord2 = df.groupby('loadingOrder')['latitude','longitude'].last().reset_index()\n",
    "        tmp_cord = dd.from_pandas(tmp_cord, npartitions=16)\n",
    "        tmp_cord[['latitude','longitude']] = tmp_cord.apply(lambda x: func(x['loadingOrder'],x['latitude'],x['longitude'],tmp_cord2),axis=1,result_type='expand')\n",
    "        tmp_cord = tmp_cord.compute()\n",
    "        tmp_cord.columns = ['loadingOrder','end_lat','end_lon']\n",
    "        group_df = group_df.merge(tmp_cord,on='loadingOrder',how='left')\n",
    "        # 增加起点经纬度\n",
    "        tmp_cord = tmp.groupby('loadingOrder')['latitude','longitude'].first().reset_index()\n",
    "        tmp_cord2 = df.groupby('loadingOrder')['latitude','longitude'].first().reset_index()\n",
    "        tmp_cord = dd.from_pandas(tmp_cord, npartitions=16)\n",
    "        tmp_cord[['latitude','longitude']] = tmp_cord.apply(lambda x: func(x['loadingOrder'],x['latitude'],x['longitude'],tmp_cord2),axis=1,result_type='expand')\n",
    "        tmp_cord = tmp_cord.compute()\n",
    "        tmp_cord.columns = ['loadingOrder','begin_lat','begin_lon']\n",
    "        group_df = group_df.merge(tmp_cord,on='loadingOrder',how='left')\n",
    "        \n",
    "        \n",
    "    elif mode=='test':\n",
    "        group_df = df.groupby('loadingOrder')['timestamp'].agg(count='count').reset_index()\n",
    "        \n",
    "        tmp_cordinate = df.groupby('loadingOrder')['end_lat','end_lon'].last().reset_index()\n",
    "        group_df = group_df.merge(tmp_cordinate, on='loadingOrder', how='left')\n",
    "\n",
    "        tmp_cordinate = df.groupby('loadingOrder')['begin_lat','begin_lon'].last().reset_index()\n",
    "        group_df = group_df.merge(tmp_cordinate, on='loadingOrder', how='left')\n",
    "        \n",
    "\n",
    "    anchor_df = df.groupby('loadingOrder')['anchor'].agg('sum').reset_index()\n",
    "    anchor_df.columns = ['loadingOrder', 'anchor_cnt']\n",
    "    group_df = group_df.merge(anchor_df, on='loadingOrder', how='left')\n",
    "    group_df['anchor_ratio'] = group_df['anchor_cnt'] / group_df['count']\n",
    "\n",
    "    agg_function = ['min', 'max', 'mean', 'median']\n",
    "    agg_col = ['latitude', 'longitude', 'speed', 'direction']\n",
    "\n",
    "    group = df.groupby('loadingOrder')[agg_col].agg(agg_function).reset_index()\n",
    "    group.columns = ['loadingOrder'] + ['{}_{}'.format(i, j) for i in agg_col for j in agg_function]\n",
    "    group_df = group_df.merge(group, on='loadingOrder', how='left')\n",
    "    \n",
    "    return group_df\n",
    "\n",
    "\n",
    "train = get_feature(train_data, mode='train')\n",
    "#print(train)\n",
    "test = get_feature(test_data, mode='test')\n",
    "#print(test)\n",
    "features = [c for c in train.columns if c not in ['loadingOrder', 'label', 'mmin', 'mmax', 'count']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 2.47418e+12\nEarly stopping, best iteration is:\n[82]\tvalid_0's l2: 2.35979e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 1.38672e+12\n[200]\tvalid_0's l2: 1.38461e+12\nEarly stopping, best iteration is:\n[138]\tvalid_0's l2: 1.32174e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 1.89807e+12\nEarly stopping, best iteration is:\n[10]\tvalid_0's l2: 1.42973e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 1.48105e+12\n[200]\tvalid_0's l2: 1.46354e+12\nEarly stopping, best iteration is:\n[162]\tvalid_0's l2: 1.37564e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 1.78516e+12\n[200]\tvalid_0's l2: 1.51634e+12\n[300]\tvalid_0's l2: 1.45234e+12\n[400]\tvalid_0's l2: 1.42675e+12\n[500]\tvalid_0's l2: 1.3844e+12\n[600]\tvalid_0's l2: 1.30239e+12\n[700]\tvalid_0's l2: 1.33234e+12\nEarly stopping, best iteration is:\n[600]\tvalid_0's l2: 1.30239e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 3.15737e+12\nEarly stopping, best iteration is:\n[17]\tvalid_0's l2: 2.82481e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 2.95708e+12\n[200]\tvalid_0's l2: 2.71594e+12\n[300]\tvalid_0's l2: 2.5688e+12\n[400]\tvalid_0's l2: 2.47016e+12\n[500]\tvalid_0's l2: 2.38388e+12\n[600]\tvalid_0's l2: 2.41493e+12\n[700]\tvalid_0's l2: 2.33511e+12\n[800]\tvalid_0's l2: 2.35911e+12\nEarly stopping, best iteration is:\n[726]\tvalid_0's l2: 2.31218e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 2.25137e+13\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 2.18416e+13\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 5.50595e+12\n[200]\tvalid_0's l2: 5.08231e+12\n[300]\tvalid_0's l2: 5.03665e+12\n[400]\tvalid_0's l2: 4.95092e+12\n[500]\tvalid_0's l2: 4.77686e+12\n[600]\tvalid_0's l2: 4.74737e+12\n[700]\tvalid_0's l2: 4.73393e+12\nEarly stopping, best iteration is:\n[621]\tvalid_0's l2: 4.71072e+12\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's l2: 2.10615e+12\nEarly stopping, best iteration is:\n[66]\tvalid_0's l2: 1.94096e+12\n"
    }
   ],
   "source": [
    "def build_model(train, test, pred, label, seed=1080, is_shuffle=True):\n",
    "    train_pred = np.zeros((train.shape[0], ))\n",
    "    test_pred = np.zeros((test.shape[0], ))\n",
    "    n_splits = 10\n",
    "    # Kfold\n",
    "    fold = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=seed)\n",
    "    kf_way = fold.split(train[pred])\n",
    "    # params\n",
    "    params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 36,\n",
    "        'metric': 'mse',\n",
    "        'feature_fraction': 0.48,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 6,\n",
    "        'seed': 8,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction_seed': 7,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'nthread': 8,\n",
    "        'verbose': 1,\n",
    "    }\n",
    "    # train\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(kf_way, start=1):\n",
    "        train_x, train_y = train[pred].iloc[train_idx], train[label].iloc[train_idx]\n",
    "        valid_x, valid_y = train[pred].iloc[valid_idx], train[label].iloc[valid_idx]\n",
    "        # 数据加载\n",
    "        n_train = lgb.Dataset(train_x, label=train_y)\n",
    "        n_valid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=n_train,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[n_valid],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "        train_pred[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration)\n",
    "        test_pred += clf.predict(test[pred], num_iteration=clf.best_iteration)/fold.n_splits\n",
    "        test_pred += DELTA/fold.n_splits\n",
    "    \n",
    "    test['label'] = test_pred\n",
    "    \n",
    "    return test[['loadingOrder', 'label']]\n",
    "\n",
    "result = build_model(train, test, features, 'label', is_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2019/10/16  23:25:38\n"
    }
   ],
   "source": [
    "test_data = test_data.merge(result, on='loadingOrder', how='left')\n",
    "test_data['ETA'] = (test_data['onboardDate'] + test_data['label'].apply(lambda x:pd.Timedelta(seconds=x)))\n",
    "mean_time = test_data['ETA'].mean().strftime('%Y/%m/%d  %H:%M:%S')\n",
    "print(mean_time)\n",
    "test_data['ETA'] = test_data['ETA'].apply(lambda x:x.strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "test_data.drop(['direction','TRANSPORT_TRACE'],axis=1,inplace=True)\n",
    "test_data['onboardDate'] = test_data['onboardDate'].apply(lambda x:x.strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "test_data['creatDate'] = pd.datetime.now().strftime('%Y/%m/%d  %H:%M:%S')\n",
    "test_data['timestamp'] = test_data['temp_timestamp']\n",
    "# 整理columns顺序\n",
    "result = test_data[['loadingOrder', 'timestamp', 'longitude', 'latitude', 'carrierName', 'vesselMMSI', 'onboardDate', 'ETA', 'creatDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         loadingOrder                 timestamp   longitude   latitude  \\\n0      CF946210847851  2019-04-02T02:42:28.000Z  138.471062  40.278787   \n1      CF946210847851  2019-04-02T02:59:28.000Z  138.552168  40.327785   \n2      CF946210847851  2019-04-02T03:07:28.000Z  138.588250  40.352542   \n3      CF946210847851  2019-04-02T03:43:28.000Z  138.751325  40.459447   \n4      CF946210847851  2019-04-02T04:29:28.000Z  138.969782  40.581485   \n...               ...                       ...         ...        ...   \n45451  XG479584941731  2019-01-13T03:56:08.000Z  104.633357   1.630708   \n45452  XG479584941731  2019-01-13T03:57:08.000Z  104.631958   1.626713   \n45453  XG479584941731  2019-01-13T03:57:38.000Z  104.631258   1.624615   \n45454  XG479584941731  2019-01-13T03:58:08.000Z  104.630597   1.622682   \n45455  XG479584941731  2019-01-13T03:59:08.000Z  104.629178   1.618552   \n\n      carrierName   vesselMMSI           onboardDate                   ETA  \\\n0          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/05/04  17:01:50   \n1          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/05/04  17:01:50   \n2          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/05/04  17:01:50   \n3          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/05/04  17:01:50   \n4          OIEQNT  R5480015614  2019/04/02  02:42:28  2019/05/04  17:01:50   \n...           ...          ...                   ...                   ...   \n45451      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/26  01:30:53   \n45452      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/26  01:30:53   \n45453      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/26  01:30:53   \n45454      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/26  01:30:53   \n45455      JCMFTA  U2218600548  2019/01/10  00:27:58  2019/01/26  01:30:53   \n\n                  creatDate  \n0      2020/06/19  01:24:07  \n1      2020/06/19  01:24:07  \n2      2020/06/19  01:24:07  \n3      2020/06/19  01:24:07  \n4      2020/06/19  01:24:07  \n...                     ...  \n45451  2020/06/19  01:24:07  \n45452  2020/06/19  01:24:07  \n45453  2020/06/19  01:24:07  \n45454  2020/06/19  01:24:07  \n45455  2020/06/19  01:24:07  \n\n[45456 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loadingOrder</th>\n      <th>timestamp</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>carrierName</th>\n      <th>vesselMMSI</th>\n      <th>onboardDate</th>\n      <th>ETA</th>\n      <th>creatDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T02:42:28.000Z</td>\n      <td>138.471062</td>\n      <td>40.278787</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/05/04  17:01:50</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T02:59:28.000Z</td>\n      <td>138.552168</td>\n      <td>40.327785</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/05/04  17:01:50</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T03:07:28.000Z</td>\n      <td>138.588250</td>\n      <td>40.352542</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/05/04  17:01:50</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T03:43:28.000Z</td>\n      <td>138.751325</td>\n      <td>40.459447</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/05/04  17:01:50</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CF946210847851</td>\n      <td>2019-04-02T04:29:28.000Z</td>\n      <td>138.969782</td>\n      <td>40.581485</td>\n      <td>OIEQNT</td>\n      <td>R5480015614</td>\n      <td>2019/04/02  02:42:28</td>\n      <td>2019/05/04  17:01:50</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45451</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:56:08.000Z</td>\n      <td>104.633357</td>\n      <td>1.630708</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/26  01:30:53</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>45452</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:57:08.000Z</td>\n      <td>104.631958</td>\n      <td>1.626713</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/26  01:30:53</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>45453</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:57:38.000Z</td>\n      <td>104.631258</td>\n      <td>1.624615</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/26  01:30:53</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>45454</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:58:08.000Z</td>\n      <td>104.630597</td>\n      <td>1.622682</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/26  01:30:53</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n    <tr>\n      <th>45455</th>\n      <td>XG479584941731</td>\n      <td>2019-01-13T03:59:08.000Z</td>\n      <td>104.629178</td>\n      <td>1.618552</td>\n      <td>JCMFTA</td>\n      <td>U2218600548</td>\n      <td>2019/01/10  00:27:58</td>\n      <td>2019/01/26  01:30:53</td>\n      <td>2020/06/19  01:24:07</td>\n    </tr>\n  </tbody>\n</table>\n<p>45456 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}